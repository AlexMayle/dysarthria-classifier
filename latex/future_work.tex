\section{Future Work}
ZCA whitening is commonly employed as a pre-processing step in many audio classification tasks \cite{zca-1} \cite{zca-2} \cite{zca-3}. Unfortunately, this proved to be intractable on our implementation machine as the co-variance matrix of the data does not fit in memory. Given the ease of computing the transformation on an appropriate machine, it is a compelling next step in an effort to improve performance. Another technique, batch normalization has also been shown to improve performance \cite{DBLP:journals/corr/CooijmansBLC16}. While we considered implementing this, the level of abstraction with which we define the LSTM model did not provide the necessary level of granularity.

Barring minor improvements made possible by more foresight, we consider architectural additions which may increase performance. The solutions discussed in this paper are monolithic, end-to-end networks. Alternatively, one may use a recursive network structure similar to the one employed in \cite{carmichael2008combining}. Different networks are trained independently, then combined to produce one, larger classifier. For example, one network may classify the speakers' gender or rate of speech first, providing more information to the next layer to use. This pattern would culminate in a final dysarthria classification layer. The model presented in \cite{DBLP:journals/corr/LeePKN17} take features much closer to the raw waveform when compared to MFCCs. Applying this approach to dysarthria classification may also prove to be effective. 